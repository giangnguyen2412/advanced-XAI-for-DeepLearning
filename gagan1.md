# Does the Whole Exceed its Parts? The Effect of AI Explanations on Complementary Team Performance
- We show that explanations increase the chance
that humans will accept the AI’s recommendation regardless of whether the AI is correct. 
- when the AI provides explanations, team accuracy reaches a level higher than human-alone
- To explore these questions, we conduct new studies where we control the study design such
that the AI’s accuracy is comparable to the human’s (Figure 1B). This decision aims at simulating
a setting where (i) there is a stronger incentive to deploy hybrid human-AI teams, and (ii) there
exists more potential for complementary performance
- we varied the representation of explanations by
explaining just the predicted class versus explaining the top-two classes
- We observed complementary performance on every task, but surprisingly,
explanations did not yield improved team performance, compared to simply showing the AI’s
confdence. Explanations increased team performance when the AI system was correct, but
decreased it when the AI erred — so the net value was minimal
