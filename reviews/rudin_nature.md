# Stop Explaining Black Box Machine Learning Models for High Stakes Decisions and Use Interpretable Models Instead

## One-sentence summary

- We don't need black box models in the first place.

- Explanation methods lend authority to the black box.

## Ideas and method

- Tabular data: decision trees, linear/additive models/scoring systems
- Raw data (text, image, sound wave): interpretable neural networks

## Evaluation

- N/A