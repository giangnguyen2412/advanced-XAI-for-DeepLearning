# Summary
This papers focuses on instance-wise feature selection as a specific approach for model interpretation. Given a machine learning model, instance-wise feature selection asks for the importance scores of each feature on the prediction of a given instance, and the relative importance of each feature are allowed to vary across instances. While feature selection produces a global importance of features with respect to the entire labeled data set, instance-wise feature selection measures feature importance locally for each instance labeled by the model. They have shown the efficiency and the capacity of the proposed approach (L2X) for instance-wise feature selection on both synthetic and real data sets. 
# Contributions
Given two random vectors X and Y, the mutual information I(X; Y) is a measure of dependence between them; intuitively, it corresponds to how much knowledge of one random vector reduces the uncertainty about the other. They propose to use mutual information as a criteria for instance-wise feature selection. However, the formulation of mutual information in intractable, so they propose to use approximation via sampling to get a tractable function, and makes use of a Gumbel-softmax relaxation of discrete subset sampling during training.
Authors propose a new approach for instance-wise feature selection based on mutual information. An instance-wise feature selector is defined (L2X) which returns a distribution over the subset of features given the input vector. During the explaining stage, the learned explainer maps each sample X to a weight vector of dimension d, each entry representing the importance of the corresponding feature for the specific sample X. In order to provide a deterministic explanation for a given sample, they rank features according to the weight vector, and the k features with the largest weights are picked as the explaining features.
Authors introduce post-hoc accuracy for quantitatively validating the effectiveness of L2X. This is a new metric in the scenario of explaining how a CNN, LSTM works. L2X is the first method to realize real-time interpretation of a black-box model. They have shown the efficiency and the synthetic and real data sets.
# Possible improvement
They would like to find out which k words make the most influence on the decision of the model in a specific review. The number of key words is fixed to be k = 10 for all the experiments. This hyper parameter strongly affects the performance of the algorithm. However, it is not well explained and seems to be chosen empirically. A better explanation and a more-fine grained method for choosing the best value of k would help.
