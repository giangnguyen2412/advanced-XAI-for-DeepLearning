# paper-review-interpretable-DL
A hub for paper reviews in Interpretable Deep Learning
### 2019
- <a name="todo"></a> GAN Dissection: Visualizing and Understanding Generative Adversarial Networks (**ICLR2019**) - [review ](https://github.com/luulinh90s/paper-review-interpretable-DL/edit/master/gan_dissect.md) 
### 2018
- <a name="todo"></a> Generating Counterfactual Explanations with Natural Language (**ICML2018**) - [review ](https://github.com/luulinh90s/paper-review-interpretable-DL/edit/master/counterfactual.md) 
- <a name="todo"></a> Interpretable Discovery in Large Image Data Sets (**ICML2018**) - [review ](https://github.com/luulinh90s/paper-review-interpretable-DL/edit/master/demud.md) 
- <a name="todo"></a> Towards Providing Explanations for AI Planner Decisions (**IJCAI/ECAI2018**) - [review ](https://github.com/luulinh90s/paper-review-interpretable-DL/edit/master/XAI-plan.md) 
- <a name="todo"></a> Learning to Explain: An Information-Theoretic Perspective on Model Interpretation (**ICML2018**) - [review ](https://github.com/luulinh90s/paper-review-interpretable-DL/edit/master/L2X.md) 
- <a name="todo"></a> Anchors: High-Precision Model-Agnostic Explanations (**AAAI2018**) - [review ](https://github.com/luulinh90s/paper-review-interpretable-DL/edit/master/anchors.md) 
### 2017
- <a name="todo"></a> Visualizing Deep Neural Network Decisions: Prediction Difference Analysis (**ICLR2017**) - [review ](https://github.com/luulinh90s/paper-review-interpretable-DL/edit/master/evidence.md) 
- <a name="todo"></a> Interpretable Deep Models for ICU Outcome Prediction (**AMIA 2016**) - [review ](https://github.com/luulinh90s/paper-review-interpretable-DL/edit/master/icu_mimic.md) 
### 2016
- <a name="todo"></a> Examples are not enough, learn to criticize! Criticism for Interpretability (**NIPS2016**) - [review ](https://github.com/luulinh90s/paper-review-interpretable-DL/edit/master/MMD-critic.md) 
- <a name="todo"></a> The Mythos of Model Interpretability (**ICML2016**) - [review ](https://github.com/luulinh90s/paper-review-interpretable-DL/edit/master/mythos.md) 
- <a name="todo"></a> Deep Neural Decision Forests (**IJCAI2016**) - [review ](https://github.com/luulinh90s/paper-review-interpretable-DL/edit/master/forests.md) 
- <a name="todo"></a> InfoGAN: Interpretable Representation Learning by Information Maximizing Generative Adversarial Nets (**NIPS2016**) - [review ](https://github.com/luulinh90s/paper-review-interpretable-DL/edit/master/info_gan.md) 
- <a name="todo"></a> "Why Should I Trust You?": Explaining the Predictions of Any Classifier (**arXiv**) - [review ](https://github.com/luulinh90s/paper-review-interpretable-DL/edit/master/lime.md) 
### 2015
- <a name="todo"></a> Understanding Neural Networks Through Deep Visualization (**ICML2015**) - [review ](https://github.com/luulinh90s/paper-review-interpretable-DL/edit/master/understandNN.md) 
### 2013
- <a name="todo"></a> Visualizing and Understanding Convolutional Networks - [review ](https://github.com/luulinh90s/paper-review-interpretable-DL/edit/master/deconvnet.md) 
